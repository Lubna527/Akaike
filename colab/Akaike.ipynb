{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install these only in a notebook/script environment\n",
        "!pip install spacy scikit-learn joblib pandas numpy tensorflow gardio\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCmDNemGM12b",
        "outputId": "78cae303-1917-46c1-da66-0382dce94478"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.7-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.7-py3-none-any.whl (23 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.12 pyngrok-7.2.7 starlette-0.46.2 uvicorn-0.34.2\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import re\n",
        "import spacy\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "class PIIMasker:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.placeholder_map = {\n",
        "            \"full_name\": \"[full_name]\",\n",
        "            \"email\": \"[email]\",\n",
        "            \"phone_number\": \"[phone_number]\",\n",
        "            \"dob\": \"[dob]\",\n",
        "            \"aadhar_num\": \"[aadhar_num]\",\n",
        "            \"credit_debit_no\": \"[credit_debit_no]\",\n",
        "            \"cvv_no\": \"[cvv_no]\",\n",
        "            \"expiry_no\": \"[expiry_no]\"\n",
        "        }\n",
        "        self.patterns = {\n",
        "            \"email\": r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
        "            \"phone_number\": r'(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b|\\b\\d{3}[-.\\s]?\\d{4}\\b',\n",
        "            \"dob\": r'\\b(?:0?[1-9]|1[0-2])[/-](?:0?[1-9]|[12][0-9]|3[01])[/-](?:19|20)?\\d{2}\\b',\n",
        "            \"aadhar_num\": r'\\b\\d{4}[ -]?\\d{4}[ -]?\\d{4}\\b',\n",
        "            \"credit_debit_no\": r'\\b(?:\\d[ -]*?){13,16}\\b',\n",
        "            \"cvv_no\": r'\\b\\d{3,4}\\b',\n",
        "            \"expiry_no\": r'\\b(?:0[1-9]|1[0-2])[/-](?:\\d{4}|\\d{2})\\b'\n",
        "        }\n",
        "\n",
        "    def mask_text(self, text: str) -> Dict[str, Any]:\n",
        "        # First pass: Protect existing placeholders\n",
        "        protected = {}\n",
        "        for pii_type, placeholder in self.placeholder_map.items():\n",
        "            pattern = re.compile(re.escape(placeholder))\n",
        "            for i, match in enumerate(pattern.finditer(text)):\n",
        "                protected[f\"PROTECTED_{pii_type}_{i}\"] = match.group()\n",
        "                text = text.replace(match.group(), f\"PROTECTED_{pii_type}_{i}\")\n",
        "\n",
        "        # Second pass: Mask new PII\n",
        "        entities = []\n",
        "        masked_text = text\n",
        "        masked_positions = set()\n",
        "\n",
        "        # 1. Mask names using spaCy\n",
        "        doc = self.nlp(masked_text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\" and len(ent.text.split()) >= 2:\n",
        "                start, end = ent.start_char, ent.end_char\n",
        "                if not any(s <= start < e or s < end <= e for (s, e) in masked_positions):\n",
        "                    original = masked_text[start:end]\n",
        "                    masked_text = masked_text[:start] + \"[full_name]\" + masked_text[end:]\n",
        "                    entities.append({\n",
        "                        \"position\": [start, end],\n",
        "                        \"classification\": \"full_name\",\n",
        "                        \"entity\": original\n",
        "                    })\n",
        "                    masked_positions.add((start, end))\n",
        "\n",
        "        # 2. Mask other PII with regex (process from end to start)\n",
        "        spans = []\n",
        "        for pii_type, pattern in self.patterns.items():\n",
        "            for match in re.finditer(pattern, masked_text):\n",
        "                start, end = match.span()\n",
        "                if not any(s <= start < e or s < end <= e for (s, e) in masked_positions):\n",
        "                    spans.append((start, end, pii_type, match.group()))\n",
        "\n",
        "        # Sort spans in reverse order to avoid offset issues\n",
        "        for start, end, pii_type, original in sorted(spans, key=lambda x: x[0], reverse=True):\n",
        "            masked_text = masked_text[:start] + self.placeholder_map[pii_type] + masked_text[end:]\n",
        "            entities.append({\n",
        "                \"position\": [start, end],\n",
        "                \"classification\": pii_type,\n",
        "                \"entity\": original\n",
        "            })\n",
        "\n",
        "        # Third pass: Restore protected placeholders\n",
        "        for protected_key, original in protected.items():\n",
        "            masked_text = masked_text.replace(protected_key, original)\n",
        "\n",
        "        return {\"masked_email\": masked_text, \"entities\": sorted(entities, key=lambda x: x[\"position\"][0])}\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(filepath: str):\n",
        "    df = pd.read_csv(filepath)\n",
        "    emails = df['email'].tolist()\n",
        "    categories = df['type'].tolist()\n",
        "    return emails, categories\n",
        "\n",
        "# Main training function\n",
        "def train_classifier():\n",
        "    # Load data\n",
        "    emails, categories = load_and_preprocess_data('/content/drive/MyDrive/combined_emails_with_natural_pii.csv')\n",
        "\n",
        "    # Initialize and apply PII masking\n",
        "    masker = PIIMasker()\n",
        "    masked_emails = [masker.mask_text(email)['masked_email'] for email in emails]\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(categories)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        masked_emails, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Vectorize text\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=5000,\n",
        "        ngram_range=(1, 2),\n",
        "        stop_words='english'\n",
        "    )\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train model\n",
        "    classifier = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced',\n",
        "        C=0.1,\n",
        "        solver='liblinear'\n",
        "    )\n",
        "    classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = classifier.predict(X_test_vec)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    # Save artifacts\n",
        "    joblib.dump(classifier, 'email_classifier.joblib')\n",
        "    joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
        "    joblib.dump(label_encoder, 'label_encoder.joblib')\n",
        "\n",
        "    return classifier, vectorizer, label_encoder\n",
        "\n",
        "# Prediction function\n",
        "def predict_email_category(email: str, classifier, vectorizer, label_encoder):\n",
        "    masker = PIIMasker()\n",
        "    masked_email = masker.mask_text(email)['masked_email']\n",
        "    email_vec = vectorizer.transform([masked_email])\n",
        "    pred = classifier.predict(email_vec)\n",
        "    return label_encoder.inverse_transform(pred)[0]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Train the model\n",
        "    print(\"Training classifier...\")\n",
        "    classifier, vectorizer, label_encoder = train_classifier()\n",
        "\n",
        "    # Test predictions\n",
        "    test_emails = [\n",
        "        \"Hello John Doe, your invoice for $100 is due on 05/30/2023. Contact us at billing@company.com\",\n",
        "        \"Password reset requested for account jane.smith@example.com\",\n",
        "        \"Your appointment with Dr. Johnson is confirmed for 06/15 at 3 PM\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTest Predictions:\")\n",
        "    for email in test_emails:\n",
        "        category = predict_email_category(email, classifier, vectorizer, label_encoder)\n",
        "        print(f\"\\nEmail: {email}\\nCategory: {category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8z907ucOViI",
        "outputId": "cdec79eb-f351-4cd7-ed25-7f2a1572e364"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier...\n",
            "Accuracy: 0.73\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Change       0.82      0.75      0.78       504\n",
            "    Incident       0.67      0.88      0.76      1917\n",
            "     Problem       0.57      0.19      0.29      1007\n",
            "     Request       0.86      0.91      0.89      1372\n",
            "\n",
            "    accuracy                           0.73      4800\n",
            "   macro avg       0.73      0.69      0.68      4800\n",
            "weighted avg       0.72      0.73      0.70      4800\n",
            "\n",
            "\n",
            "Test Predictions:\n",
            "\n",
            "Email: Hello John Doe, your invoice for $100 is due on 05/30/2023. Contact us at billing@company.com\n",
            "Category: Problem\n",
            "\n",
            "Email: Password reset requested for account jane.smith@example.com\n",
            "Category: Incident\n",
            "\n",
            "Email: Your appointment with Dr. Johnson is confirmed for 06/15 at 3 PM\n",
            "Category: Incident\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import spacy\n",
        "import re\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the trained model, vectorizer, and label encoder\n",
        "classifier = joblib.load('email_classifier.joblib')\n",
        "vectorizer = joblib.load('tfidf_vectorizer.joblib')\n",
        "label_encoder = joblib.load('label_encoder.joblib')\n",
        "\n",
        "class PIIMasker:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.placeholder_map = {\n",
        "            \"full_name\": \"[full_name]\",\n",
        "            \"email\": \"[email]\",\n",
        "            \"phone_number\": \"[phone_number]\",\n",
        "            \"dob\": \"[dob]\",\n",
        "            \"aadhar_num\": \"[aadhar_num]\",\n",
        "            \"credit_debit_no\": \"[credit_debit_no]\",\n",
        "            \"cvv_no\": \"[cvv_no]\",\n",
        "            \"expiry_no\": \"[expiry_no]\"\n",
        "        }\n",
        "        self.patterns = {\n",
        "            \"email\": r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b',\n",
        "            \"phone_number\": r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{2,3}\\)?[-.\\s]?\\d{2,4}[-.\\s]?\\d{4}\\b',\n",
        "            \"dob\": r'\\b(?:0?[1-9]|1[0-2])[/-](?:0?[1-9]|[12][0-9]|3[01])[/-](?:19|20)?\\d{2}\\b',\n",
        "            \"aadhar_num\": r'\\b\\d{4}[ -]?\\d{4}[ -]?\\d{4}\\b',\n",
        "            \"credit_debit_no\": r'\\b(?:\\d[ -]*?){13,16}\\b',\n",
        "            \"cvv_no\": r'\\b\\d{3,4}\\b',\n",
        "            \"expiry_no\": r'\\b(?:0[1-9]|1[0-2])[/-](?:\\d{4}|\\d{2})\\b'\n",
        "        }\n",
        "\n",
        "    def mask_text(self, text: str):\n",
        "        # First pass: Protect existing placeholders\n",
        "        protected = {}\n",
        "        for pii_type, placeholder in self.placeholder_map.items():\n",
        "            pattern = re.compile(re.escape(placeholder))\n",
        "            for i, match in enumerate(pattern.finditer(text)):\n",
        "                protected[f\"PROTECTED_{pii_type}_{i}\"] = match.group()\n",
        "                text = text.replace(match.group(), f\"PROTECTED_{pii_type}_{i}\")\n",
        "\n",
        "        # Second pass: Mask new PII\n",
        "        # 1. Mask using regex patterns\n",
        "        for pii_type, pattern in self.patterns.items():\n",
        "            text = re.sub(\n",
        "                pattern,\n",
        "                self.placeholder_map[pii_type],\n",
        "                text\n",
        "            )\n",
        "\n",
        "        # 2. Mask names using spaCy\n",
        "        doc = self.nlp(text)\n",
        "        spans = []\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\":\n",
        "                # Check if this is a multi-word name\n",
        "                if len(ent.text.split()) >= 2:\n",
        "                    spans.append((ent.start_char, ent.end_char))\n",
        "\n",
        "        # Replace from end to start to avoid offset issues\n",
        "        for start, end in sorted(spans, reverse=True):\n",
        "            text = text[:start] + \"[full_name]\" + text[end:]\n",
        "\n",
        "        # Third pass: Restore protected placeholders\n",
        "        for protected_key, original in protected.items():\n",
        "            text = text.replace(protected_key, original)\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "def classify_and_mask_email(email_body):\n",
        "    masker = PIIMasker()\n",
        "\n",
        "    # Mask PII\n",
        "    masked_email = masker.mask_text(email_body)\n",
        "\n",
        "    # Classify\n",
        "    email_vector = vectorizer.transform([masked_email])\n",
        "    predicted_class = classifier.predict(email_vector)\n",
        "    predicted_category = label_encoder.inverse_transform(predicted_class)\n",
        "\n",
        "    return masked_email, predicted_category[0]\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=classify_and_mask_email,\n",
        "    inputs=\"text\",\n",
        "    outputs=[gr.Textbox(label=\"Masked Email\"), gr.Textbox(label=\"Category\")], # Label the outputs here\n",
        "    live=True,\n",
        "    title=\"Email PII Masking & Classification\",\n",
        "    description=\"This app masks PII in an email and classifies the email category.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "BE3kyvxlewIF",
        "outputId": "fb7bb6f2-a353-4112-8961-5fedbc334f2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://69cb9d6d2593673c13.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://69cb9d6d2593673c13.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}
